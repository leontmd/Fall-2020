{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple Perceptron:\n",
    "\n",
    "This notebook will attempt to guide you through the implementation of simple Perceptron. If everything goes right, in the end you should be able to use your code to visualize the training process as an animation. Start running the cells and fill in the missing code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing libraries for manipulating vectors (`numpy`) and for plotting (all the others below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Color settings for plotting\n",
    "colors = ['darkred', 'royalblue']\n",
    "colors_region = ['mistyrose', 'lightsteelblue']\n",
    "cmap = ListedColormap(colors)\n",
    "cmap_region = ListedColormap(colors_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to set the random seed to ensure that two different runs of the learning algorithm produce the same results. Of course, the learning algorithm should not work for just this one random seed we pick. We do this only to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) #Setting a random seed is important for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "We're going to create a 2d dataset by combining clusters generated by two gaussians with means (0, 0), (3, 3) and unit variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(num_samples):\n",
    "    size = num_samples // 2\n",
    "    x1 = np.random.multivariate_normal([0, 0], np.eye(2), size)\n",
    "    y1 = -np.ones(size).astype(int)\n",
    "    x2 = np.random.multivariate_normal([3, 3], np.eye(2), size)\n",
    "    y2 = np.ones(size).astype(int)\n",
    "    \n",
    "    X = np.vstack((x1, x2))\n",
    "    y = np.append(y1, y2)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convenient thing about a two dimensional dataset is that we can actually visualize it on this notebook. Let's write a helper function to plot the two dimensional dataset consisting of instances (`x`) and labels (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(x, y):\n",
    "    fig = plt.figure(figsize = (7, 5), dpi = 100, facecolor = 'w')\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y, edgecolor='black', cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a training set with 150 examples and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generate_data(150)\n",
    "plot(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "Now, you will need to fill in the remaining functions using what we have seen in class. To help your implementation, you can use the hard coded values below for debugging/testing your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These values will be used to test your implementations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_t = np.array([1., -1.])\n",
    "b_t = 0.5\n",
    "X_t = np.array([-0.1, 0.8, 0.5, 0.5, -0.5, -0.5, 0, 0, -0.5, 0.5]).reshape(5, 2)\n",
    "x_t = np.array([0.3, 0.3])\n",
    "y_t = -1\n",
    "lr_t = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Function\n",
    "\n",
    "Implement a function that predicts on input points using the weight vector w and the bias b.  \n",
    "Remember that the decision rule is defined by:  \n",
    "$w^Tx + b \\ge 0 \\rightarrow 1$  \n",
    "$w^Tx + b < 0 \\rightarrow -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    X: input vector or set of vectors\n",
    "    w: weight vector\n",
    "    b: bias\n",
    "    \n",
    "    Output: a numpy array containing the predictions produced by the linear threshold unit defined by w and b.\n",
    "'''\n",
    "def predict(X, w, b):\n",
    "    #FILL IN\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(X_t, w_t, b_t) #output should be: array([-1.,  1.,  1.,  1., -1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(x_t, w_t, b_t)  #output should be: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Function\n",
    "Implement a function that outputs the accuracy of the linear classifier on inputs X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    X: set of input vectors\n",
    "    y: set of labels\n",
    "    w: weight vector\n",
    "    b: bias\n",
    "    \n",
    "    Output: The accuracy achieved by the classifier defined by w and b on samples X.\n",
    "'''\n",
    "def accuracy(X, y, w, b):\n",
    "    #FILL IN\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(X_t, np.ones(X_t.shape[0]), w_t, b_t) #output should be 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Function\n",
    "Implement the Perceptron update defined by:  \n",
    "$w_{new} \\leftarrow w_{old} + r*(y*x)$  \n",
    "$b_{new} \\leftarrow b_{old} + r*y$  \n",
    "\n",
    "Where $r$ is the learning rate, $y$ is the label and $x$ is the training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    x: input vector\n",
    "    y: label\n",
    "    w: weight vector\n",
    "    b: bias\n",
    "    lr: learning rate\n",
    "    \n",
    "    Updates the w and b according to the Perceptron update rule.\n",
    "    \n",
    "    Output: updated w and b\n",
    "'''\n",
    "def update(x, y, w, b, lr):\n",
    "    #FILL IN\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update(x_t, y_t, w_t, b_t, lr_t) #output should be: (array([ 0.97, -1.03]), 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing updates\n",
    "In order to be able to visualize the training process we need to store all of the updates during training. The class defined below is designed to do exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    A class that will handle the storage of the historic values of training\n",
    "'''\n",
    "class History:\n",
    "    def __init__(self, num_epochs):\n",
    "        self.training_hist = dict()\n",
    "        for n in range(num_epochs):\n",
    "            self.training_hist[n] = {'w_hist': [], \n",
    "                                'b_hist': [], \n",
    "                                'acc_hist': [],\n",
    "                                'point_hist':[]}\n",
    "    def store(self, x, y, w, b, accuracy, epoch):\n",
    "        self.training_hist[epoch]['point_hist'].append((x, y))\n",
    "        self.training_hist[epoch]['w_hist'].append(w.copy())\n",
    "        self.training_hist[epoch]['b_hist'].append(b)\n",
    "        self.training_hist[epoch]['acc_hist'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each update in the Perceptron algorithm call the store function with the necessary inputs.  \n",
    "- x, y: the point on which the mistake was made and the corresponding label of that point.\n",
    "- w, b: the updated weight vector and bias\n",
    "- accuracy: the accuracy over the entire training set (calculated with the new w and b)\n",
    "- epoch: the current epoch number  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling samples\n",
    "\n",
    "Before each epoch we need to randomly shuffle the samples. The function below will take your samples and the labels and shuffle them with the same order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_arrays(X, y):\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Algorithm\n",
    "Piece the functions together and implement the Perceptron algorithm.  \n",
    "https://svivek.com/teaching/machine-learning/lectures/slides/perceptron/perceptron.pdf (Slide 12)  \n",
    "Below is a pseudocode for the algorithm:\n",
    "\n",
    "    initialize w and b \n",
    "    for each epoch\n",
    "        shuffle the training samples\n",
    "        for each x, y pair:\n",
    "            predict class of x using w, b\n",
    "            if mistake\n",
    "                update w and b\n",
    "     return w, b\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, epochs=10, lr=0.01):\n",
    "    hist = History(epochs)\n",
    "    w = np.random.uniform(0, 1, size=X_train.shape[1]) #initialize w\n",
    "    b = 0 #initialize bias\n",
    "    \n",
    "    #FILL IN\n",
    "        \n",
    "    return w, b, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, hist = train(X_train, y_train, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(X_train, y_train, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training\n",
    "\n",
    "While we can't really visualize training in general for $d$-dimensional datasets (if $d>2$), since we are looking at the two dimensional case, we can visualize how training proceeds as a video. \n",
    "\n",
    "The visualize function below will use your implementations to create an animation of the training process. \n",
    "\n",
    "You *may* need to download FFmpeg to render the animation. https://github.com/adaptlearning/adapt_authoring/wiki/Installing-FFmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Given all the updates during training, creates an animation that shows how the decision boundary was affected.\n",
    "'''\n",
    "def visualize(X, Y, epoch_hist):\n",
    "    fig = plt.figure(figsize = (7, 5), dpi = 100, facecolor = 'w')\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor='black', cmap=cmap)\n",
    "    plots = []\n",
    "    for e in epoch_hist:\n",
    "        epoch_values = epoch_hist[e]\n",
    "        w_hist = epoch_values['w_hist']\n",
    "        b_hist = epoch_values['b_hist']\n",
    "        acc_hist = epoch_values['acc_hist']\n",
    "        point_hist = epoch_values['point_hist']\n",
    "        for i in range(len(w_hist)):\n",
    "            w, b = w_hist[i], b_hist[i]     \n",
    "            acc = acc_hist[i]\n",
    "            if i+1 < len(point_hist):\n",
    "                p_x, p_y = point_hist[i+1]\n",
    "            else:\n",
    "                p_x, p_y = point_hist[i]\n",
    "            Z = predict(np.c_[xx.ravel(), yy.ravel()], w, b)\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            plot =  plt.contourf(xx, yy, Z, cmap=cmap_region)\n",
    "            text = f'Epoch: {e + 1} - Accuracy: {round(acc, 3)}'\n",
    "            te = plt.text(90, 90, text)\n",
    "            an = plt.annotate(text, xy=(0.3, 1.05), xycoords='axes fraction')\n",
    "            points = plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor='black', cmap=cmap)\n",
    "            c_idx = 1 if p_y == 1 else 0\n",
    "            if i+1 < len(point_hist):\n",
    "                p = plt.scatter(x=p_x[0], y=p_x[1], s=100, c=colors[c_idx], edgecolor='black')\n",
    "                plots.append(plot.collections + [te, an, points, p])\n",
    "            else:\n",
    "                plots.append(plot.collections + [te, an, points])\n",
    "    return animation.ArtistAnimation(fig, plots, repeat=False, blit=False, interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ani = visualize(X_train, y_train, hist.training_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_html5_video()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ani.save('perceptron.mp4') #If you want to store the animation as a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment:\n",
    "Play around with different learning rates and initializations. Can you explain what's going on?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
